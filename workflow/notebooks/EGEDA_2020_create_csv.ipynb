{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EGEDA cleaning script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For cleaning the October EGEDA energy balance tables excel file provided by ESTO 13 October 2022.\n",
    "##### This script will create a csv with years across the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_today = datetime.now().strftime('%d%m%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw data\n",
    "\n",
    "RawEGEDA = pd.read_excel('../../data/October_2022/00APEC.xlsx',\n",
    "                         sheet_name = None, # 'None' reads in all sheets\n",
    "                         na_values = ['x', 'X', '']) # I don't think there's any x's or X's in the EGEDA xlsx file, but leaving as is (shouldn't make a difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "economies = RawEGEDA.keys()\n",
    "economy_dict = pd.read_csv('../../data/economy_dict.csv', header = None, index_col = 0).squeeze('columns').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7844, 44), (7844, 43), (7844, 44), (7844, 44), (7844, 43)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_of_data = []\n",
    "\n",
    "for economy in economies:\n",
    "    dimension = RawEGEDA[economy].shape\n",
    "    shape_of_data.append(dimension)\n",
    "\n",
    "shape_of_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert whether each data sheet has the same number of rows\n",
    "\n",
    "def row_check(list):\n",
    "    return all(i == list[0] for i in list)\n",
    "\n",
    "number_of_rows = [i[0] for i in shape_of_data]\n",
    "\n",
    "assert row_check(number_of_rows) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name the first two columns which are currently blank\n",
    "for economy in economies:\n",
    "    RawEGEDA[economy].rename(columns = {'Unnamed: 0': 'product_code', 'Unnamed: 1': 'item_code'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some regions have 2021 data but it is incomplete, and so we only want data to 2020\n",
    "years = list(range(1980, 2021, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for economy in economies:\n",
    "    _df_economy = RawEGEDA[economy]\n",
    "    _df = pd.melt(_df_economy, \n",
    "                  id_vars = ['product_code', 'item_code'], \n",
    "                  value_vars = years, \n",
    "                  var_name = 'year',\n",
    "                  value_name = 'value'\n",
    "                )\n",
    "    #_df = _df.pivot_table(index=['Year','Product Code'],columns='Item Code',values='Value')\n",
    "    _df['economy'] = economy_dict[economy]\n",
    "    _df = _df.set_index(['economy', 'year'])\n",
    "    df_list.append(_df)\n",
    "\n",
    "df = pd.concat(df_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "# And remove multiple spaces from variables\n",
    "df['product_code'] = df['product_code'].replace('\\s+', ' ', regex = True)\n",
    "df['item_code'] = df['item_code'].replace('\\s+', ' ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_code\n",
    "df['product_code'] = df['product_code'].str.lower()\n",
    "df['product_code'] = df['product_code'].str.replace(' ', '_', regex = False)\\\n",
    "                                       .str.replace('.', '_', regex = False)\\\n",
    "                                       .str.replace('/', '_', regex = False)\\\n",
    "                                       .str.replace('(', '', regex = False)\\\n",
    "                                       .str.replace(')', '', regex = False)\\\n",
    "                                       .str.replace('-', '', regex = False)\\\n",
    "                                       .str.replace(',', '', regex = False)\\\n",
    "                                       .str.replace('&', 'and', regex = False)\\\n",
    "                                       .str.replace('___', '_', regex = False)\\\n",
    "                                       .str.replace('__', '_', regex = False)\\\n",
    "                                       .str.replace(':', '', regex = False)\\\n",
    "                                       .str.rstrip('_')\n",
    "\n",
    "# item_code\n",
    "df['item_code'] = df['item_code'].str.lower()\n",
    "df['item_code'] = df['item_code'].str.replace(' ', '_', regex = False)\\\n",
    "                                 .str.replace('.', '_', regex = False)\\\n",
    "                                 .str.replace('/', '_', regex = False)\\\n",
    "                                 .str.replace('(', '', regex = False)\\\n",
    "                                 .str.replace(')', '', regex = False)\\\n",
    "                                 .str.replace('-', '', regex = False)\\\n",
    "                                 .str.replace(',', '', regex = False)\\\n",
    "                                 .str.replace('&', 'and', regex = False)\\\n",
    "                                 .str.replace('___', '_', regex = False)\\\n",
    "                                 .str.replace('__', '_', regex = False)\\\n",
    "                                 .str.replace(':', '', regex = False)\\\n",
    "                                 .str.rstrip('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary amendment\n",
    "df['product_code'] = df['product_code'].str.replace('_0', '_', regex = False)\n",
    "df['product_code'] = df['product_code'].str.replace('1_refinery_gas', '10_refinery_gas', regex = False)\n",
    "df['product_code'] = df['product_code'].str.replace('liqour', 'liquor', regex = False)\n",
    "df['item_code'] = df['item_code'].str.replace('_0', '_', regex = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1_production', '2_imports', '3_exports', '4_international_marine_bunkers']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just having a quick look at the newly named values in item_code \n",
    "list(df.loc[:,'item_code'].unique())[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>product_code</th>\n",
       "      <th>item_code</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">01_AUS</th>\n",
       "      <th>1980</th>\n",
       "      <td>1_coal</td>\n",
       "      <td>1_production</td>\n",
       "      <td>2172.907332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>1_coal</td>\n",
       "      <td>2_imports</td>\n",
       "      <td>0.041868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             product_code     item_code        value\n",
       "economy year                                        \n",
       "01_AUS  1980       1_coal  1_production  2172.907332\n",
       "        1980       1_coal     2_imports     0.041868"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>product_code</th>\n",
       "      <th>item_code</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">06_HKC</th>\n",
       "      <th>1980</th>\n",
       "      <td>1_coal</td>\n",
       "      <td>1_production</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>1_coal</td>\n",
       "      <td>2_imports</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             product_code     item_code  value\n",
       "economy year                                  \n",
       "06_HKC  1980       1_coal  1_production    NaN\n",
       "        1980       1_coal     2_imports    NaN"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are NaN's as per below check\n",
    "df[df['value'].isna()].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change NaN's to zeroes\n",
    "\n",
    "df['value'] = df['value'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input thermal coal variable/subtotal\n",
    "\n",
    "thermal_df = df[df['product_code'].isin(['1_2_other_bituminous_coal', '1_3_subbituminous_coal', '1_4_anthracite', '3_peat', '4_peat_products'])]\n",
    "\n",
    "assert thermal_df.value.isna().sum() == 0\n",
    "\n",
    "df1 = thermal_df.groupby(['economy', 'year', 'item_code'])['value'].sum().reset_index().assign(product_code = '1_x_coal_thermal').set_index(['economy', 'year'])\n",
    "\n",
    "df1 = pd.concat([df, df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And also insert NGL aggregate variable\n",
    "\n",
    "NGL_df = df1[df1['product_code'].isin(['6_2_natural_gas_liquids', '6_3_refinery_feedstocks', '6_4_additives_oxygenates', '6_5_other_hydrocarbons'])]\n",
    "\n",
    "assert NGL_df.value.isna().sum() == 0\n",
    "\n",
    "df2 = NGL_df.groupby(['economy', 'year', 'item_code'])['value'].sum().reset_index().assign(product_code = '6_x_ngls').set_index(['economy', 'year'])\n",
    "\n",
    "df2 = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And also insert NGL aggregate variable\n",
    "\n",
    "otherpet_df = df2[df2['product_code'].isin(['7_12_white_spirit_sbp', '7_13_lubricants', '7_14_bitumen', '7_15_paraffin_waxes', '7_16_petroleum_coke', '7_17_other_products'])]\n",
    "\n",
    "assert otherpet_df.value.isna().sum() == 0\n",
    "\n",
    "df3 = otherpet_df.groupby(['economy', 'year', 'item_code'])['value'].sum().reset_index().assign(product_code = '7_x_other_petroleum_products').set_index(['economy', 'year'])\n",
    "\n",
    "df3 = pd.concat([df2, df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now jet fuel aggregate variable\n",
    "\n",
    "jetfuel_df = df3[df3['product_code'].isin(['7_4_gasoline_type_jet_fuel', '7_5_kerosene_type_jet_fuel'])]\n",
    "\n",
    "assert jetfuel_df.value.isna().sum() == 0\n",
    "\n",
    "df4 = jetfuel_df.groupby(['economy', 'year', 'item_code'])['value'].sum().reset_index().assign(product_code = '7_x_jet_fuel').set_index(['economy', 'year'])\n",
    "\n",
    "df4 = pd.concat([df3, df4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16_x_hydrogen fuel (not needed for FED but is needed for TPES)\n",
    "\n",
    "hydrogen_df = df4[df4['product_code'] == '16_9_other_sources'].copy()\n",
    "\n",
    "assert hydrogen_df.value.isna().sum() == 0\n",
    "\n",
    "hydrogen_df.loc[:, 'value'] *= 0\n",
    "\n",
    "df5 = hydrogen_df.groupby(['economy', 'year', 'item_code'])['value'].sum().reset_index().assign(product_code = '16_x_hydrogen').set_index(['economy', 'year'])\n",
    "\n",
    "df5 = pd.concat([df4, df5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy = df5.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing new variable category names\n",
    "# pd.concat([pd.DataFrame(df5.loc[:,'product_code'].unique()),\\\n",
    "#            pd.DataFrame(df5.loc[:,'item_code'].unique())], axis = 1)\\\n",
    "#             .to_csv('../../results/product_item_list_Oct2022.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load correct order of fuel code and item code. Update this csv based on new entries or desired order\n",
    "\n",
    "ordered = pd.read_csv('../../data/order_Oct2022_egeda.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorder fuel code and item code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This grabs the unique values of fuel_code and item_code_new in the order they appear in the original dataframe. It removes 'na' by calling '[:-1]' \n",
    "\n",
    "order1 = list(ordered['product_code'].unique())[:-1]\n",
    "order2 = list(ordered['item_code'])\n",
    "\n",
    "# Take order defined above and define each of the variables as categorical in that already established order (for the benefit of viewing data later)\n",
    "\n",
    "df_tidy['product_code'] = pd.Categorical(df_tidy['product_code'], \n",
    "                                      categories = order1, \n",
    "                                      ordered = True)\n",
    "\n",
    "df_tidy['item_code'] = pd.Categorical(df_tidy['item_code'],\n",
    "                                          categories = order2,\n",
    "                                          ordered = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy_sorted = df_tidy.sort_values(['product_code', 'item_code']).reset_index(drop = True)\n",
    "# df_tidy_sorted[df_tidy_sorted['fuel_code'] == '1_3_subbituminous_coal'] #1_1_3_subbituminous_coal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, pivot the tidy dataset to provide it in wide format similar to RawEGEDA (so years are across the top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years = df_tidy_sorted.pivot_table(index = ['economy', 'product_code', 'item_code'], columns = 'year', values = 'value').reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years.to_csv('../../results/EGEDA_2020_created_' + date_today + '.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "151ce216a8b9cb792d5840c4cdba857758b5f5eb9053ba8237c0ca4c6fe482f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
