{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EGEDA cleaning script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For cleaning the EGEDA data sent by Edito: EGEDA_2018.xlsx"
   ]
  },
  {
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import re"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d0af4ae780a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw data\n",
    "\n",
    "RawEGEDA = pd.read_excel('../../data/EGEDA_2018.xlsx',\n",
    "                         sheet_name = None,\n",
    "                         na_values = ['x', 'X', '']) # I don't think there's any x's or X's in the EGEDA xlsx file, but leaving as is (shouldn't make a difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RawEGEDA.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1980, 2019, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RawEGEDA['20_USA'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RawEGEDA['20_USA']['Item Code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "economies = RawEGEDA.keys()\n",
    "\n",
    "for economy in economies:\n",
    "    _df_economy = RawEGEDA[economy]\n",
    "    _df = pd.melt(_df_economy, \n",
    "                  id_vars = ['Product Code', 'Item Code'], \n",
    "                  value_vars = years, \n",
    "                  var_name = 'year',\n",
    "                  value_name = 'value'\n",
    "                )\n",
    "    #_df = _df.pivot_table(index=['Year','Product Code'],columns='Item Code',values='Value')\n",
    "    _df['economy'] = economy\n",
    "    _df = _df.set_index(['economy', 'year'])\n",
    "    df_list.append(_df)\n",
    "\n",
    "df = pd.concat(df_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Product Code'] == '1.1 Coking coal'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "# And remove multiple spaces from variables\n",
    "df['product_code'] = df['product_code'].replace('\\s+', ' ', regex = True)\n",
    "df['item_code'] = df['item_code'].replace('\\s+', ' ', regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change product code and item code names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuel_code'] = df['product_code']\n",
    "df['item_code_new'] = df['item_code']\n",
    "\n",
    "# new fuel_code\n",
    "df['fuel_code'] = df['fuel_code'].str.lower()\n",
    "df['fuel_code'] = df['fuel_code'].str.replace(' ', '_').str.replace('.', '_').str.replace('/', '_').str.replace('(', '').str.replace(')', '').str.replace('-', '') \\\n",
    ".str.replace(',', '').str.replace('&', 'and').str.rstrip('_')\n",
    "\n",
    "# item_code_new\n",
    "df['item_code_new'] = df['item_code_new'].str.lower()\n",
    "df['item_code_new'] = df['item_code_new'].str.replace(' ', '_').str.replace('.', '_').str.replace('/', '_').str.replace('(', '').str.replace(')', '').str.replace('-', '') \\\n",
    ".str.replace(',', '').str.replace('&', 'and').str.rstrip('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.loc[:,'fuel_code'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dictionary of EGEDA Product Codes and APERC Fuel codes\n",
    "(No longer used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.fuel_code == '1_1_coking_coal'].head() # spot check aligns with EGEDA raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate columns\n",
    "\n",
    "df = df[['fuel_code', 'item_code_new', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.fuel_code == '1_1_coking_coal'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input thermal coal variable/subtotal\n",
    "\n",
    "thermal_df = df[df['fuel_code'].isin(['1_2_other_bituminous_coal', '1_3_subbituminous_coal', '1_4_anthracite', '3_peat','4_peat_products'])]\n",
    "assert thermal_df.value.isna().sum() == 0\n",
    "\n",
    "df1 = thermal_df.groupby(['economy', 'year', 'item_code_new'])['value'].sum().reset_index().assign(fuel_code = '1_x_coal_thermal').set_index(['economy', 'year']).append(df)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1['fuel_code'] == '1_3_subbituminous_coal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1['fuel_code'] == '1_x_coal_thermal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And also insert NGL aggregate variable\n",
    "\n",
    "NGL_df = df1[df1['fuel_code'].isin(['6_2_natural_gas_liquids', '6_3_refinery_feedstocks', '6_4_additives_oxygenates', '6_5_other_hydrocarbons'])]\n",
    "\n",
    "assert NGL_df.value.isna().sum() == 0\n",
    "\n",
    "df2 = NGL_df.groupby(['economy', 'year', 'item_code_new'])['value'].sum().reset_index().assign(fuel_code = '6_x_ngls').set_index(['economy', 'year']).append(df1)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[:,'item_code_new'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before changing ktoe to PJ, remove rows with data in Gwh\n",
    "\n",
    "gwh_to_pj_df = df2[df2['item_code_new'] == '18__electricity_output_in_gwh']\n",
    "\n",
    "gwh_to_pj_conversion = 0.0036\n",
    "\n",
    "# electricity gwh data changed to pj\n",
    " \n",
    "gwh_to_pj_df = gwh_to_pj_df.assign(pj = np.multiply(gwh_to_pj_df['value'], gwh_to_pj_conversion))  \n",
    "gwh_to_pj_df['item_code_new'] = '18__electricity_output_in_gwh'\n",
    "\n",
    "gwh_to_pj_df.columns = ['item_code_new', 'ktoe', 'fuel_code', 'pj']\n",
    "gwh_to_pj_df = gwh_to_pj_df[['fuel_code', 'item_code_new', 'ktoe', 'pj']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwh_to_pj_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in PJ columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to PJ\n",
    "\n",
    "conversion_to_PJ = 1 # 41.868 PJ = 1 million tonnes of oil equivalent\n",
    "# http://w.astro.berkeley.edu/~wright/fuel_energy.html\n",
    "\n",
    "df_pj = df2[df2['item_code_new'] != '18__electricity_output_in_gwh']\n",
    "\n",
    "df_pj = df_pj.assign(pj = np.multiply(df_pj['value'], conversion_to_PJ))\n",
    "df_pj.columns = ['item_code_new', 'ktoe', 'fuel_code', 'pj']\n",
    "df_pj = df_pj[['fuel_code', 'item_code_new', 'ktoe', 'pj']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now append df_pj to gwh_pj_df (so all data is now in PJ)\n",
    "\n",
    "df = df_pj.append(gwh_to_pj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['fuel_code'] == '1_3_subbituminous_coal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy[df_tidy['fuel_code'] == '1_3_subbituminous_coal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load correct order of fuel code and item code. Update this csv based on new entries or desired order\n",
    "\n",
    "ordered = pd.read_csv('../../data/order_2018.csv')\n",
    "ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ordered['fuel_code'].unique())[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reorder fuel code and item code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This grabs the unique values of fuel_code and item_code_new in the order they appear in the original dataframe. It removes 'na' by calling '[:-1]' \n",
    "\n",
    "order1 = list(ordered['fuel_code'].unique())[:-1]\n",
    "order2 = list(ordered['item_code_new'])\n",
    "\n",
    "# Take order defined above and define each of the variables as categorical in that already established order (for the benefit of viewing data later)\n",
    "\n",
    "df_tidy['fuel_code'] = pd.Categorical(df_tidy['fuel_code'], \n",
    "                                      categories = order1, \n",
    "                                      ordered = True)\n",
    "\n",
    "df_tidy['item_code_new'] = pd.Categorical(df_tidy['item_code_new'],\n",
    "                                          categories = order2,\n",
    "                                          ordered = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy_sorted = df_tidy.sort_values(['fuel_code', 'item_code_new']).reset_index()\n",
    "df_tidy_sorted[df_tidy_sorted['fuel_code'] == '1_3_subbituminous_coal'] #1_1_3_subbituminous_coal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop ktoe column and save as tidy data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tidy_sorted = df_tidy_sorted.drop(['index', 'ktoe'], axis = 1)\n",
    "#df_tidy_sorted.to_csv(\"../../results/EGEDA_2018_tidy.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tidy_sorted[df_tidy_sorted['fuel_code'] == '1_x_coal_thermal'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View df\n",
    "\n",
    "df_tidy_sorted.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, pivot the tidy dataset to provide it in wide format similar to RawEGEDA (so years are across the top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years = df_tidy_sorted.pivot_table(index = ['economy', 'fuel_code', 'item_code_new'], columns = 'year', values = 'pj').reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_years.to_csv(\"../../results/EGEDA_2018_years.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years.to_excel(\"../../results/EGEDA_2018_years.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And now pivot so item codes are along the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = df_tidy_sorted\n",
    "df_items['item_code_new'] = df_items['item_code_new'].astype(str)\n",
    "\n",
    "df_items = df_items.pivot_table(index = ['economy', 'fuel_code', 'year'], columns = 'item_code_new', values = 'pj').reset_index()\n",
    "\n",
    "# Reorder columns based on order2 defined above\n",
    "\n",
    "NewOrder = ['economy', 'fuel_code', 'year']\n",
    "NewOrder.extend(order2) \n",
    "\n",
    "df_items = df_items[NewOrder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_items.to_csv(\"../../results/EGEDA_2018_items.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.to_excel(\"../../results/EGEDA_2018_items.xlsx\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}